{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# kor-eng translation model - 1 / 220908\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZkpXARQCjddS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Transfer Learning\n",
        "2.   Hugging face\n",
        "3.   Helsinki-NLP/opus-mt-ko-en\n",
        "\n"
      ],
      "metadata": {
        "id": "9n7w3M_Ij3-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Transfer Learning"
      ],
      "metadata": {
        "id": "iWn8Nje1kSsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 좋은 딥러닝 모델을 만드려면 많은 수의 데이터를 확보해야 함. 하지만 프로젝트를 진행하면서 충분히 많은 데이터를 확보하고 학습하기에는 어려움이 있음.\n",
        "\n",
        "\n",
        "이를 해결하기 위해 **Transfer Learning(전이학습) 활용**.\n",
        "\n",
        "\n",
        "전이 학습이란, 이미 특정 분야의 대규모 데이터 셋으로 잘 학습된 신경망 모델(**Pretrained model)을 활용**해 새로운 분야에서 사용되는 신경망의 학습에 이용하는 방법.\n",
        "\n",
        "\n",
        "학습데이터의 수가 적을 때 효과적이며, 전이학습 없이 학습할 때보다 훨씬 높은 정확도와 더 빠른 학습 속도 제공.\n",
        "\n",
        "Fine-tuning : 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정하여 학습시키는 방법"
      ],
      "metadata": {
        "id": "lxSA0o3KksuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Hugging face"
      ],
      "metadata": {
        "id": "wN0a6H6VoIJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Huggingface는 transformer를 기반으로 하는 다양한 모델(transformer.models)와 학습 스크립트(transformer.Trainer)를 구현해 놓은 모듈\n",
        "\n",
        "홈페이지 : https://huggingface.co/\n",
        "\n",
        "문서 : https://huggingface.co/docs/transformers/index\n"
      ],
      "metadata": {
        "id": "Pm-tVvBJ-9uX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제) 감정 분석 모델 불러오고, 활용하기 \n",
        "/ 입력된 텍스트의 감정을 별 수(1~5개)로 예측\n",
        "\n",
        "https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n"
      ],
      "metadata": {
        "id": "M3T3bIz_BedT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformers 패키지 설치\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02JAaf-HB-TY",
        "outputId": "1ea27bc3-2f60-4732-b7e2-1bcc59823e7c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 사용할 pretrained model의 이름이나 경로\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "# pretrained model 불러오기 \n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# pretrined tokenizer 불러오기\n",
        "# tokenizer는 입력을 token으로 바꾸는 역할을 함\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "furw7UnTAdKe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# pipeline()은 pretrained model을 사용하는 가장 쉬운 방법\n",
        "# task, model, tokenizer 순서로 parameter 전달하면 됨.\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "Iyu7bR3CA-YJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"This product is really nice.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45yw-nr4BPsh",
        "outputId": "c0db7799-b9ac-4d2c-db08-7d59b6faf141"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '5 stars', 'score': 0.6608336567878723}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"It's not bad.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa5twxLVCWqN",
        "outputId": "3da79f0e-ce93-4962-bba9-58749abb5cfe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '3 stars', 'score': 0.46596336364746094}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"It's very bad.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgakuAE6Cc-M",
        "outputId": "507f5bd9-33b6-40d0-cde4-84a79de2706c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '1 star', 'score': 0.4941597580909729}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Helsinki-NLP/opus-mt-ko-en"
      ],
      "metadata": {
        "id": "WGHZ62HhBPNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "kor->eng 번역 pretrained model\n",
        "\n",
        "\n",
        "https://huggingface.co/Helsinki-NLP/opus-mt-ko-en"
      ],
      "metadata": {
        "id": "8I9rOZxcGhDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 예제처럼 transformers 패키지를 설치해주고, \n",
        "\n",
        "추가로 해당 모델의 tokenizer가 필요로 하는 패키지를 설치해야함.\n",
        "\n",
        "\n",
        "\n",
        "설치 코드 \n",
        "\n",
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "K7UdjjGwG6X-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 예제는 분류 모델이여서 AutoModelForSequenceClassification를 import하고 사용했지만,\n",
        "\n",
        "번역 모델은 대신 AutoModelForSeq2SeqLM를 import하고 사용해야함."
      ],
      "metadata": {
        "id": "f05shpS5Hegl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "번역모델의 pipeline task는 'translation_xx_to_yy' "
      ],
      "metadata": {
        "id": "UGrBo3tGHyWV"
      }
    }
  ]
}